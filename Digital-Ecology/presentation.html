<!DOCTYPE HTML>
<html>
<head>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
<title>Concrete Jumble</title>
<link href="main.css" rel="stylesheet" type="text/css">
<style>
div.img {
    border: 1px solid #ccc;
}

div.img:hover {
    border: 1px solid #777;
}

div.img img {
    width: 100%;
    height: auto;
}

div.desc {
    padding: 15px;
    text-align: center;
}

* {
    box-sizing: border-box;
}

.responsive {
    padding: 0 6px;
    float: left;
    width: 24.99999%;
}

@media only screen and (max-width: 700px){
    .responsive {
        width: 49.99999%;
        margin: 6px 0;
    }
}

@media only screen and (max-width: 500px){
    .responsive {
        width: 100%;
    }
}

.clearfix:after {
    content: "";
    display: table;
    clear: both;
}

header {	
    background-image: url("photos/Red Hook/canal.jpg");
	background-repeat: no-repeat;
	background-position: center;
	width: 100%;
}
</style>
</head>

<body>

<ul>
 <li><a class="active" href="index.html">Home</a></li>
  <li><a class="active" href="assignments.html">Site Map</a></li>
  <li><a class ="active" href="gallery.html">Gallery</a></li>
  <li><a class = "active" href="sound.html">Audio</a></li>
  <li><a class="active" href="video.html">Video</a></li>
  <li><a class="active" href="https://digitalmediatheory.wordpress.com/author/jamesjfan/">Blog</a></li>
  <ul style="float:right;list-style-type:none;">
    <li><a class="active" href="about.html">About</a></li>
  </ul>
</ul>

<header>

	<h1>Software Studies: a Lexicon
		</h1> 
 <h3>The Computational Federalist - Centralization and the Agency of Logic
 
 </h3>
	</header>
<div>




</div> 


<div>
	
		<section>
        
  <p>Complexity is easy, understanding is hard. To know anything at all, it seems, is a struggle. Whether it’s the heuristic reductions that human reason makes, or the logic systems we ourselves create, at some level things become complicated. Software in particular is a many-headed beast in its unpacking. A beast, ironically,that we created in the first place. Yet, our creation of machines and their processes by no means gives us dominion over them. They do, however, give us an a reflective insight into how we build and understand logics. In Matthew Fuller’s Software Studies: a Lexicon, he writes in his introduction about the dangerous dichotomy in which we try and understand software and digital objects, or any complex subject. On one hand there is a tendency to want to either “interpret the banal” with comparisons to software from terms in other fields by “stating that the subject is now ‘complex’ and somehow therefore familiarly sublime in its difficulty” by inserting our own references (Fuller 11). The other side to this duality is “abjectly loving that which is given” and fully accepting the divinity of the complex (Fuller 11). Neither are particularly villainous choices, and in varying degrees have their merits, but they share the common underlying assumption of definitive knowledge.
  </p>
  <p>
Whether that definitive is one that wraps up knowledge neatly into a bow and synthesizes the familiarity of other fields of knowledge (tangential or otherwise), or if the definitive is the acceptance of complexity in itself (due to a percieved futility to be understood), both commit to comfort. There is nothing wrong with intellectual comfort in and of itself, but it begets a certain mindset, one where the capacity of knowledge is not as valued. This ability to take in that which is uncomfortable, or not as easily reasoned, becomes harder to grasp. Not because we don’t seek it, but because it means we accept a more practical or familiar interpretation of events and trajectories. It’s hard to relate to the unrelatable, to the dissonant, or the strange. Even in this paper, I’ll have to connect thoughts and ideas to a relatable ideal or notion just to convey information coherently, which I find no problem in (because pretension in withholding knowledge you can translate I think is more dangerous). However, in the context of software which Fuller talks about, I think this lexicon is exactly trying to mediate the strange and obscure to those who do not directly work with software (and even then there are gaps in knowledge for those who do work with software). The lexicon in itself is not just a dictionary whose purpose is to define, but “is a vocabulary of terms used in a particular subject” or discourse (Fuller 8). And to understand anything it first must be related to through some sort of mediation, in Fuller’s case that mediation is language and the terms themselves.
</p>
<p>
 The first steps in trying to grasp the unfamiliar, or the strange in the familiar, is to explain what something is and then dissect its components. In chapters like Algorithm, Buttons, Copy, Intelligence and other sections these writers and scholars are trying to unpack these very loaded words which are used to describe and talk about software. And in turn, they facilitate Fuller’s Nietzschean goal of taking the realm of software and cross-examining it so that we see its xenoform, rather than its familiar form (Fuller 11). In the breakdown of the term Algorithm it describes this “unifying concept” and the base at which computer science is derived before it is uniquely implemented into a particular program environment (Fuller 15). And rather than perpetuating the connotations of an algorithm as all-knowing and powerful ingredient the writer, Andrew Goffrey, simply defines it as controlled logic used to solve a particular problem (Fuller 15). Algorithms do things, but without “concrete machinery” those interactions “would only be a paper reality” and it is this connection to the concrete and the computed conceptualization that becomes our translation (Fuller 17). 
 </p>
 <p>
Michel Foucault says in the text in his The Archaeology of Knowledge “to speak is to do something—something other than to express what one thinks, to translate what one knows,” and this can be used to think about “machinic discourse” (Fuller 17-18). That brings up the question, what is the machine talking to? We may insert and translate our algorithms into machines, but algorithms do nothing in a vacuum, they need structured knowledge (or data structures) to work off of and from. Whether categorized as analog or digital, these machines have to have connect not only to us and our human input, but with the rest of the itself (or other machines). It’s a complex interplay between input, algorithm, output, and nested logic. The more we interact with computers, with buttons, GUI’s, and mice and keyboards, the more computers are transversally influenced by ideology and our own translation of logic.
</p>
<p>
Visualization in its essence is our translation and interpretive process with computers. They “are created for people rather than for machines” but at the same time “a visualization is not a representation but a means to a representation” (Fuller 79). We try to mediate a computer’s non-perceptive or visual processing capabilities so we can also do something that we can distill information. To be coherent in a human sense, our logics themselves need to be discrete, connected and nested, but discrete in their statements nonetheless. This is where our own cognitive bias comes into play in the centralization of computational knowledge (or data structures), and how they are formatted in order to maximize computational resource use and efficiency. But what this centralization of logic also produces is an avenue of reasoning, logic gates and pathways that lead toward very particular ways to think about something (mainly, yes or no) because the nebulousness of the maybe/possibly is harder to centralize and conceptualize.
</p>
<p>
In the section Function, it says “the same input must always—if this thing is rational, if it’s a machine—produce the same result” (Fuller 105). This is a particularly deterministic outcome, and implies efficient causality in the computational universe. However, in the actual physical universe efficient causality, while easy to understand and distill information from, does not always correlate with the logics of emergent causality that the universe is built upon. And in a machine even when something seems random it is actually calculated randomness. The exception to this tunneled logic “would be a class of reversible logic functions that at some point might emerge from pure theory to find practical uses in cryptography and / or quantum computing”  (Fuller 106). It seems these reversible logic gates and asymmetric algorithms with “one-to-many” outputs would be the key organizational structure to fully and more completely compute stranger logics (Fuller 106). 
</p>
<p>
Cross-examining logic is important, but now is the time where I begin to question Matthew Fuller’s quest for the complication and the xeno-mediation of software. The dissection of the familiar or strange is in itself can be a process but for what ends? In the pragmatic sense that extends beyond theory, what does making the world strange accomplish? I agree that it is a noble goal that increases our capacity rather than comfort of knowledge, and in turn breeds a context of holistic understanding where ideas and further knowledge can coalesce. Yet, like Communism’s advocacy of constant revolution, the revolution soon becomes the establishment. When does capacity become instituted? I ask this, because unless there is a very drastic cognitive evolution in our logic and perceptional processes we will still need a frame of reference to even interact with the multi-faceted rhizomic computational machinic-organism. This is why some centralization, even in a system where logics are less humanistically determined and have their own agency, the centralized structure (at the very least at a descriptive/interactional level) is needed for us to actually use software. The advocacy of logic system dissection and xeno-mediation is important, but in its very essence if we are to interact with it (as software is designed to do at least in part) we need to be able to relate with it. 
</p>
	

<p align="center">Works Cited</p>
<p align="center">
Fuller, Matthew. Software Studies: A Lexicon. Cambridge, MA: MIT, 2008. 1-142. Print.

  </p>



				</section>


<section>

<p>


</p>
</section>

	</div>
<nav>
		<ul>
			<li> <a href="assignments.html">Go to Site Map</a> 
  
			</li>
           
	
			</ul>
		</nav>



	</div>
</section>

	</div>
    

<footer>
<h5><a href="index.html">Back to Homepage</a></h5>




    
  


	


    
   <a rel="license" href="http://creativecommons.org/licenses/by-nc/4.0/"><img alt="Creative Commons License" style="border-width:0" src="https://i.creativecommons.org/l/by-nc/4.0/88x31.png" /></a><br />This work is licensed under a <a rel="license" href="http://creativecommons.org/licenses/by-nc/4.0/">Creative Commons Attribution-NonCommercial 4.0 International License</a>.
<p>
This website is for educaitonal purposes only at New York University.
</p>
</footer>




</body>
</html>